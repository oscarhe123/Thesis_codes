{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7b2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import torch\n",
    "from DataHandlers import *\n",
    "#from nn_models.NN_model_BN import *\n",
    "from nn_models.lstm_unet import UNet_ConvLSTM\n",
    "from nn_models.DBlink_NN import *\n",
    "\n",
    "from Trainers_ULM import *\n",
    "from Utils import *\n",
    "from demo_exp_params import *\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from utils.utilities import *\n",
    "# from torchview import draw_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d42e1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "path = r'./' # Path to model\n",
    "\n",
    "tmp_result_dir_exist = os.path.exists(\"./tmp_results\")\n",
    "if not tmp_result_dir_exist:\n",
    "   # Create a tmp_results dir because it does not exist\n",
    "   os.makedirs(\"./tmp_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530ba83",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4ee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "method = 'DBlinkBase'  # options : DeepSMV / DBlink / Reg_Unet / DBlinkBase\n",
    "\n",
    "TrainNetFlag = False\n",
    "\n",
    "if(TrainNetFlag):\n",
    "    X_train = torch.load('X_train')\n",
    "    y_train = torch.load('y_train')\n",
    "    X_val = torch.load('X_val')\n",
    "    y_val = torch.load('y_val')\n",
    "\n",
    "if method == 'DBlink':\n",
    "    \n",
    "    # model parameters\n",
    "    model_name = 'DBlink_model'\n",
    "    img_size = 128 \n",
    "    num_layers = 2 # The number of LSTM layers\n",
    "    hidden_channels = 4 # The hidden layer number of channels at the output of each lstm cell. Purpose?: adding more combinations of features? -> Higher complexity. It's more features.\n",
    "    window_size = 12 # The number of used windows (in each direction) for the inference of each reconstructed frame\n",
    "\n",
    "    model = ConvOverlapBLSTM(input_size=(img_size, img_size), input_channels=1, hidden_channels=hidden_channels, num_layers=num_layers, device=device).to(device)  #DBlink\n",
    "    \n",
    "    if(TrainNetFlag):\n",
    "        \n",
    "        #training parameters \n",
    "        lr = 1e-3 # Training learning rate #was 1e-4\n",
    "        betas = (0.99, 0.999) # Parameters of Adam optimizer\n",
    "        epochs = 40\n",
    "        batch_size =4\n",
    "        patience = 5 # was 8\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=patience, min_lr=1e-9, verbose=True)\n",
    "        \n",
    "        # loading data \n",
    "        \n",
    "        y_train = y_train[:,[4],:]\n",
    "        y_val = y_val[:,[4],:]\n",
    "        \n",
    "        dl_train = CreateDataLoader(X_train, y_train, batch_size=batch_size)\n",
    "        dl_val = CreateDataLoader(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        trainer = DBlink_trainer(model, criterion, optimizer, scheduler, batch_size, window_size=window_size,\n",
    "                                   vid_length=X_train.shape[1], patience=patience, device=device, modelname = model_name)\n",
    "        trainer.fit(dl_train, dl_val, num_epochs=epochs)\n",
    "        #torch.save(model.state_dict(), model_name)\n",
    "        \n",
    "    else:  # Testing\n",
    "        model.load_state_dict(torch.load(model_name, map_location=torch.device(device)))\n",
    "        \n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "        \n",
    "    \n",
    "\n",
    "elif method == 'DBlinkBase':\n",
    "    \n",
    "    # model parameters\n",
    "    model_name = 'DBlinkBase_model'\n",
    "    img_size = 32\n",
    "    num_layers = 2 # The number of LSTM layers\n",
    "    hidden_channels = 4 # The hidden layer number of channels at the output of each lstm cell. Purpose?: adding more combinations of features? -> Higher complexity. It's more features.\n",
    "    window_size = 25 # The number of used windows (in each direction) for the inference of each reconstructed frame\n",
    "\n",
    "    model = ConvOverlapBLSTM(input_size=(img_size, img_size), input_channels=1, hidden_channels=hidden_channels, num_layers=num_layers, device=device).to(device)  #DBlink\n",
    "    \n",
    "    if(TrainNetFlag):\n",
    "        \n",
    "        #training parameters \n",
    "        lr = 1e-4 # Training learning rate #was 1e-4\n",
    "        betas = (0.99, 0.999) # Parameters of Adam optimizer\n",
    "        epochs = 1\n",
    "        batch_size = 16\n",
    "        patience = 3 # was 8\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=patience, min_lr=1e-9, verbose=True)\n",
    "        \n",
    "        # loading data \n",
    "        if(TrainNetFlag):\n",
    "            \n",
    "            X_train = torch.load('BaseX_train')\n",
    "            y_train = torch.load('Basey_train')\n",
    "            X_val = torch.load('BaseX_val')\n",
    "            y_val = torch.load('Basey_val')\n",
    "        \n",
    "        #y_train = y_train[:,[4],:]\n",
    "        #y_val = y_val[:,[4],:]\n",
    "        \n",
    "        dl_train = CreateDataLoader(X_train, y_train, batch_size=batch_size)\n",
    "        dl_val = CreateDataLoader(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        trainer = LSTM_overlap_Trainer(model, criterion, optimizer, scheduler, batch_size, window_size=window_size,\n",
    "                                   vid_length=X_train.shape[1], patience=patience, device=device, modelname = model_name)\n",
    "        trainer.fit(dl_train, dl_val, num_epochs=epochs)\n",
    "        #torch.save(model.state_dict(), model_name)\n",
    "        \n",
    "    else:  # Testing\n",
    "        model.load_state_dict(torch.load(model_name, map_location=torch.device(device)))\n",
    "    \n",
    "    \n",
    " #----------------------------------------------------------------------------------------------------------   \n",
    "    \n",
    "elif method == \"DeepSMV\":\n",
    "    \n",
    "    # model parameters\n",
    "    model_name = 'DeepSMV_model' \n",
    "    num_lstm_layers = 1 \n",
    "    in_ch = 1  \n",
    "    out_ch = 1 \n",
    "\n",
    "    #model = UNet_ConvLSTM(n_channels=1, n_classes=1, use_LSTM=True, parallel_encoder=False, lstm_layers=1).to(device)  #DeepSMV original \n",
    "    model = UNet_ConvLSTM(n_channels= in_ch, n_classes= out_ch, use_LSTM=True, parallel_encoder=False, lstm_layers= num_lstm_layers).to(device)  #DeepSMV original \n",
    "    \n",
    "    if(TrainNetFlag):\n",
    "        \n",
    "        #training parameters \n",
    "        lr = 1e-3  \n",
    "        betas = (0.99, 0.999) \n",
    "        epochs = 40\n",
    "        batch_size =8\n",
    "        patience = 3 # was 8\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=patience, min_lr=1e-9, verbose=True)\n",
    "        \n",
    "        # loading data \n",
    "        y_train = y_train[:,[4],:]  #velocitymap\n",
    "        y_val = y_val[:,[4],:]      #velocitymap\n",
    "        \n",
    "        dl_train = CreateDataLoader(X_train, y_train, batch_size=batch_size)\n",
    "        dl_val = CreateDataLoader(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        trainer = Deepsmv_trainer(model, criterion, optimizer, scheduler, batch_size,\n",
    "                                   vid_length=X_train.shape[1], patience=patience, device=device ,modelname = model_name)\n",
    "        trainer.fit(dl_train, dl_val, num_epochs=epochs)\n",
    "        #torch.save(model.state_dict(), model_name)\n",
    "        \n",
    "    else:  # Testing\n",
    "        model.load_state_dict(torch.load(model_name, map_location=torch.device(device)))\n",
    "        \n",
    "        \n",
    "#---------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "elif method == 'Reg_Unet':\n",
    "    \n",
    "    # model parameters\n",
    "    model_name = 'Reg_Unet_model' \n",
    "    num_lstm_layers = 1 \n",
    "    in_ch = 2\n",
    "    out_ch = 1 \n",
    "    LSTM_used = False\n",
    "\n",
    "    #model = UNet_ConvLSTM(n_channels=1, n_classes=1, use_LSTM=True, parallel_encoder=False, lstm_layers=1).to(device)  #DeepSMV original \n",
    "    model = UNet_ConvLSTM(n_channels= in_ch, n_classes= out_ch, use_LSTM= LSTM_used, parallel_encoder=False, lstm_layers= num_lstm_layers).to(device)  #DeepSMV original \n",
    "    \n",
    "    if(TrainNetFlag):\n",
    "        \n",
    "        #training parameters \n",
    "        lr = 1e-3 \n",
    "        betas = (0.99, 0.999) \n",
    "        epochs = 100\n",
    "        batch_size = 4\n",
    "        patience = 5 # was 8\n",
    "        #criterion = nn.L1Loss()\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=patience, min_lr=1e-9, verbose=True)\n",
    "        \n",
    "        # loading data \n",
    "        X_train = y_train[:,[3,1],:]\n",
    "        X_val = y_val[:,[3,1],:]\n",
    "        \n",
    "        y_train = y_train[:,[4],:]  #velocitymap\n",
    "        y_val = y_val[:,[4],:]      #velocitymap\n",
    "        \n",
    "        dl_train = CreateDataLoader(X_train, y_train, batch_size=batch_size)\n",
    "        dl_val = CreateDataLoader(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        trainer = Deepsmv_trainer(model, criterion, optimizer, scheduler, batch_size,\n",
    "                                   vid_length=X_train.shape[1], patience=patience, device=device,modelname = model_name)\n",
    "        trainer.fit(dl_train, dl_val, num_epochs=epochs )\n",
    "        #torch.save(model.state_dict(), model_name)\n",
    "        \n",
    "    else:  # Testing\n",
    "        model.load_state_dict(torch.load(model_name, map_location=torch.device(device)))\n",
    "    \n",
    "else:\n",
    "    print('check model name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8712105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.up)\n",
    "print(trainer.down)\n",
    "print(trainer.out_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d4f1c",
   "metadata": {},
   "source": [
    "## Testing model\n",
    "## SKIP ONLY THIS CELL BELOW IF U WANNA TEST DBLINK !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_test = torch.load('X_test')\n",
    "y_test = torch.load('y_test')\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "    \n",
    "#model_name = 'best_model'\n",
    "#model.load_state_dict(torch.load(model_name, map_location=torch.device(device)))\n",
    "\n",
    "GT = y_test    \n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "        \n",
    "    if method == 'DBlink':   \n",
    "        GT = y_test[:,4,:] \n",
    "        out = model(X_test,torch.flip(X_test, dims=[1]))\n",
    "        realout = out[:,window_size,0]\n",
    "    elif method =='DeepSMV':\n",
    "        GT = y_test[:,[4],:]\n",
    "        realout,_ = model(X_test)\n",
    "        #realout = realout[:,0,:,:]\n",
    "    elif method == 'Reg_Unet':\n",
    "        GT = y_test[:,[4],:] \n",
    "        print(GT.shape)\n",
    "        \n",
    "        realout,_ = model(y_test[:,[3,1],:])\n",
    "        print(realout.shape)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print('check method name')    \n",
    "    #print(out.shape)\n",
    "    #print(realout.shape)\n",
    "    #print(y_test.shape)\n",
    "        \n",
    "    criterion = nn.MSELoss()\n",
    "    Metric=criterion(realout,GT) # MSE \n",
    "    print(np.sqrt(Metric.item())) \n",
    "    \n",
    "    # realout = realout.detach().cpu().numpy()\n",
    "    # GT = GT.detach().cpu().numpy()\n",
    "\n",
    "    \n",
    "folder = r'./tmp_results'\n",
    "        \n",
    "realout = normalize_images(realout)\n",
    "print(realout.shape)\n",
    "print(realout.dtype)\n",
    "GT = normalize_images(GT)\n",
    "\n",
    "tracks = normalize_images(y_test[:,[3],:])\n",
    "        \n",
    "#realout = realout[:,None,:]\n",
    "#GT = GT[:,None,:]\n",
    "        \n",
    "torchvision.utils.save_image(realout, f\"{folder}/inference.png\")\n",
    "torchvision.utils.save_image(GT, f\"{folder}/GT.png\")\n",
    "torchvision.utils.save_image(tracks, f\"{folder}/input.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4d254",
   "metadata": {},
   "source": [
    "## DBLink testing HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2e9a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test = torch.load('BaseX_test')\n",
    "y_test = torch.load('Basey_test')\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "N, T, C, H, W = X_test.shape\n",
    "\n",
    "model_name = 'DBlinkBase_model'\n",
    "\n",
    "model = ConvOverlapBLSTM(input_size=(img_size, img_size), input_channels=1, hidden_channels=hidden_channels, num_layers=num_layers, device=device).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(path, model_name), map_location=torch.device(device)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebdf3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass through the network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:32<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M.S.E.:   631.3927001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:00<00:00, 48251.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Completed vid 1\n",
      "Forward pass through the network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:31<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M.S.E.:   640.6298828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:00<00:00, 49580.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Completed vid 2\n",
      "Forward pass through the network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:32<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M.S.E.:   2763.0439453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:00<00:00, 42473.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Completed vid 3\n",
      "Forward pass through the network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:31<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M.S.E.:   5.891513347625732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 300/300 [00:00<00:00, 49768.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Completed vid 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "down = torch.zeros(X_test.size(1), requires_grad=False, dtype=torch.int)\n",
    "up = torch.zeros(X_test.size(1), requires_grad=False, dtype=torch.int)\n",
    "out_ind = torch.zeros(X_test.size(1), requires_grad=False, dtype=torch.int)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "sum_factor = 1\n",
    "\n",
    "for i in range(X_test.size(1)):\n",
    "    down[i] = torch.max(torch.IntTensor([0, i -  window_size]))\n",
    "    up[i] = torch.min(torch.IntTensor([X_test.size(1), i +  window_size]))\n",
    "    out_ind[i] = i - down[i]\n",
    "\n",
    "for i in range(X_test.size(0)):\n",
    "    #i = 3\n",
    "    out = []\n",
    "    print('Forward pass through the network')\n",
    "    with torch.no_grad():\n",
    "        for j in tqdm(range(X_test.shape[1])):\n",
    "            curr_out = model(X_test[i:i + 1, down[j]:up[j]:sum_factor],\n",
    "                              torch.flip(X_test[i:i + 1, down[j]:up[j]:sum_factor], dims=[1]))\n",
    "            curr_out = curr_out.detach().cpu()[0, int(out_ind[j] / sum_factor)]\n",
    "            out.append(curr_out)\n",
    "\n",
    "    out = torch.stack(out, dim=1)\n",
    "    temp_output = out.to(device)\n",
    "\n",
    "    metric = criterion(temp_output,y_test[[i],:,0,:])\n",
    "    print('M.S.E.:  ',metric.item()) \n",
    "    del temp_output\n",
    "\n",
    "    curr_vid = np.zeros([1, X_test.size(1), C, H, W])\n",
    "    for j in tqdm(range(X_test.size(1))):\n",
    "        curr_vid[0, j] = 255 * normalize_input_01(out[0, j].numpy())\n",
    "\n",
    "    np.save('tmp_results/np_vid_{}'.format(i + 1), curr_vid[0, :-2*window_size])\n",
    "    np.save('tmp_results/gt_vid_{}'.format(i + 1), y_test[i, :-2*window_size].detach().cpu().numpy())\n",
    "\n",
    "    print(\"-I- Completed vid\", i + 1)\n",
    "    \n",
    "    #break\n",
    "    \n",
    "    ## CANNOT POST PROCESS_RESULTS IN GPU CLUSTER, do this line below on your own pc\n",
    "\n",
    "    # Post process reconstruction and generate output video\n",
    "    post_process_results(r'./tmp_results', i + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a0fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
